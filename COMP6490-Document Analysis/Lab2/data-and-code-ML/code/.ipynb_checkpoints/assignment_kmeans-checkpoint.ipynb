{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Clustering using KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your task is to code up K-means clustering as discussed in lecture and apply it to the [*Assignment 2 Q1* Data posted to Wattle](https://wattlecourses.anu.edu.au/mod/resource/view.php?id=1130230).\n",
    "Parts of the code and extensive instructions are provided in the rest of this notebook.\n",
    "Read them carefully in order to receive full marks.\n",
    "Note that there are four implementation tasks: one is to implement KMeans, and the other three are at the end of the notebook.\n",
    "\n",
    "During the lab, you will be asked to run your code on a *new* data set, similar to the *Assignment 2 Q1 Data*, but containing different documents.\n",
    "Consider this as a **train/test split**: during the development of your assignment, you observe the **training set**.\n",
    "During the lab, you are evaluated on the **testing set**.\n",
    "As you will notice below, the code displays the *top 5 document filenames* for each of the K clusters found. \n",
    "The tutor will both inspect the quality (purity and the homogeneity measure) of the clustering (2.5 pts), as well as the *efficiency* of the code you write and your explanation of your design choices (2.5 pts).\n",
    "\n",
    "**Notes:**  \n",
    "\n",
    "* If your algorithm randomizes its initialization, we are allowed to run it multiple times and we will grade the best clustering found.\n",
    "* The starting code uses the preprocessing function that we have developed during the tutorials. Feel free to experiment with other techniques to improve performance (ask Google, read the lectures etc.) We will give additional marks to such experimentations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## some configurations for notebook and importing modules\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading dataset and preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the dataset and we preprocess it in a similar manner to the tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>70337</td>\n",
       "      <td>misc.forsale</td>\n",
       "      <td>From: kedz@bigwpi.WPI.EDU (John Kedziora)\\nSub...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>74150</td>\n",
       "      <td>misc.forsale</td>\n",
       "      <td>From: myoakam@cis.ohio-state.edu (micah r yoak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>74720</td>\n",
       "      <td>misc.forsale</td>\n",
       "      <td>From: gt1706a@prism.gatech.EDU (Maureen L. Eag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>74721</td>\n",
       "      <td>misc.forsale</td>\n",
       "      <td>From: Mike Diack &lt;mike-d@staff.tc.umn.edu&gt;\\nSu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>74722</td>\n",
       "      <td>misc.forsale</td>\n",
       "      <td>From: jvinson@xsoft.xerox.com (Jeffrey A Vinso...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id      category                                               text\n",
       "0  70337  misc.forsale  From: kedz@bigwpi.WPI.EDU (John Kedziora)\\nSub...\n",
       "1  74150  misc.forsale  From: myoakam@cis.ohio-state.edu (micah r yoak...\n",
       "2  74720  misc.forsale  From: gt1706a@prism.gatech.EDU (Maureen L. Eag...\n",
       "3  74721  misc.forsale  From: Mike Diack <mike-d@staff.tc.umn.edu>\\nSu...\n",
       "4  74722  misc.forsale  From: jvinson@xsoft.xerox.com (Jeffrey A Vinso..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from data import read_as_df\n",
    "## TODO start\n",
    "## provide path to the dataset\n",
    "path_to_dataset = '../data/assign_data_test/'\n",
    "## TODO stop\n",
    "\n",
    "dataset = read_as_df(path_to_dataset)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the preprocessing function developed in the tutorials, and present in the file `prepros.py`. \n",
    "If you decide to make any improvements to the pre-processing, make it in a block in this notebook, as the tutors don't have access to any external files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [kedz, bigwpi, wpi, edu, john, kedziora, subje...\n",
       "1    [myoakam, cis, edu, micah, r, yoakam, subject,...\n",
       "2    [prism, gatech, edu, maureen, l, eagl, subject...\n",
       "3    [mike, diack, staff, tc, umn, edu, subject, ma...\n",
       "4    [jvinson, xsoft, xerox, com, jeffrey, vinson, ...\n",
       "Name: tokens, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "stopwords_en = set(stopwords.words('english'))\n",
    "\n",
    "__tokenization_pattern = r'''(?x)          # set flag to allow verbose regexps\n",
    "        \\$?\\d+(?:\\.\\d+)?%?  # currency and percentages, e.g. $12.40, 82%\n",
    "      | (?:[A-Z]\\.)+        # abbreviations, e.g. U.S.A.\n",
    "      | \\w+(?:-\\w+)*        # words with optional internal hyphens\n",
    "      | \\.\\.\\.              # ellipsis\n",
    "      | [][.,;\"'?():_`-]    # these are separate tokens; includes ], [\n",
    "    '''\n",
    "tokenizer = nltk.tokenize.regexp.RegexpTokenizer(__tokenization_pattern)\n",
    "\n",
    "def preprocessor(text):\n",
    "    stems = []\n",
    "    tokens = tokenizer.tokenize(text.lower())\n",
    "\n",
    "    for token in tokens:\n",
    "        if token.isalpha() and token not in stopwords_en:\n",
    "            stems.append(str(stemmer.stem(token)))\n",
    "    return stems\n",
    "\n",
    "dataset['tokens'] = dataset['text'].apply(preprocessor)\n",
    "dataset['tokens'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Implementing K-Means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The skeleton for kmeans algorithm is given in the next block. You have to implement/complete the following functions. The details of the functions, input, output are defined here after, or in the comments of each function.:\n",
    "\n",
    "1. **init_centroids**: Initializes the centroids (you can experiment here with random init, kmeans++ init etc).\n",
    "2. **cost**: returns the total distance between documents and the centroid for each cluster\n",
    "3. **reassign**: returns the new document labels (after the centroids have been updated)\n",
    "4. **recompute**: returns the new centroids (after the labels have been updated)\n",
    "5. **fit**: The algorithm that iteratively updates labels and centroids until convergence\n",
    "6. **get_n_documents**: return the index of top n (e.g. top 5) documents in each cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from dist import dist, search\n",
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, ClusterMixin, TransformerMixin\n",
    "import scipy\n",
    "\n",
    "class KMeans(BaseEstimator, ClusterMixin, TransformerMixin):\n",
    "    '''\n",
    "        Custom implementation of KMeans that fits to sklearn's pipeline\n",
    "    '''\n",
    "\n",
    "    ## Don't modify this constructor\n",
    "    def __init__(self, K, max_iter = 100, distance = 'cosine', tol = 1e-3):\n",
    "        '''\n",
    "            constructor for KMeans class\n",
    "\n",
    "            arguments:\n",
    "                - K: number of clusters\n",
    "                - max_iter: max number of iterations\n",
    "                - distance: distace measure to use - 'cosine' or 'euclid'\n",
    "                - tol: tolerance for convergence\n",
    "        '''\n",
    "\n",
    "        assert K >= 1, ('invalid K , must be +ve')\n",
    "        assert max_iter >= 1, ('invalid max_iter, must be +ve')\n",
    "        assert tol > 0 and tol < 1, ('tol must be in rangd (0, 1)')\n",
    "\n",
    "        self.K = K\n",
    "        self.max_iters = max_iter\n",
    "        self.dist = distance\n",
    "        self.centroids = None\n",
    "        self.labels = None\n",
    "        self.tolerance = tol\n",
    "\n",
    "    def init_centroids(self, X):\n",
    "        '''\n",
    "            this method returns the initial centroids\n",
    "            input =>\n",
    "                - X : data matrix (n * d dims)\n",
    "            output: =>\n",
    "                - centroids: centroids matrix (k * d dims)\n",
    "        '''\n",
    "\n",
    "        n, d = X.shape\n",
    "        idx = np.random.choice(n, self.K)\n",
    "\n",
    "        return X[idx, :]\n",
    "\n",
    "    def cost(self, X):\n",
    "        '''\n",
    "            this method returns the sum of distance between centroid and points for each cluster\n",
    "            input =>\n",
    "                - X : data matrix (n * d dims)\n",
    "            output: =>\n",
    "                - dists: vector of length k where dists[i] is sum of distance\n",
    "                            between centroid[i] and points that lie in cluster i\n",
    "        '''\n",
    "        costs = np.zeros(self.K)\n",
    "        for k in range(self.K):\n",
    "            costs[k] = dist(X[np.where(self.labels == k)[0], :], self.centroids[k], self.dist).sum()\n",
    "        return costs\n",
    "\n",
    "    def reassign(self, X):\n",
    "        '''\n",
    "            this method returns the new labels for each data point in X\n",
    "            input =>\n",
    "                - X : data matrix (n * d dims)\n",
    "            output: =>\n",
    "                - labels: vector of length n where labels[i] is the\n",
    "                    cluster label for ith point\n",
    "        '''\n",
    "        n, d = X.shape\n",
    "        new_assign = np.zeros(n)\n",
    "        for i in range(n):\n",
    "            new_assign[i] = np.argmin(dist(self.centroids, X[i], self.dist))\n",
    "        return new_assign\n",
    "\n",
    "    def recompute(self, X):\n",
    "        '''\n",
    "            this method returns new centroids\n",
    "            input =>\n",
    "                - X : data matrix (n * d dims)\n",
    "            output: =>\n",
    "                - centroids: new centroids computed from labels\n",
    "        '''\n",
    "        n, d = X.shape\n",
    "        centroids = np.zeros((self.K, d))\n",
    "        for k in range(self.K):\n",
    "            centroids[k] = np.average(X[np.where(self.labels == k)[0], :], 0)\n",
    "        return centroids\n",
    "\n",
    "    def fit(self, X, y = None):\n",
    "        '''\n",
    "            this method is the body of the KMeans algorithm. It regroups the data X into k clusters\n",
    "            input =>\n",
    "                - X : data matrix (n * d dims)\n",
    "            output: =>\n",
    "                - self\n",
    "        '''\n",
    "        if type(X) == scipy.sparse.csr.csr_matrix:\n",
    "            X = X.toarray()\n",
    "\n",
    "        n_iter = 0\n",
    "        converged = False\n",
    "        self.centroids = self.init_centroids(X)\n",
    "        self.labels = self.reassign(X)\n",
    "        oldObj = self.cost(X).sum()\n",
    "\n",
    "        ## iterate\n",
    "        while n_iter < self.max_iters and not converged:\n",
    "            self.centroids = self.recompute(X)\n",
    "            self.labels = self.reassign(X)\n",
    "            obj = self.cost(X).sum()\n",
    "            if oldObj - obj < self.tolerance:\n",
    "                converged = True\n",
    "            oldObj = obj\n",
    "            print('iter = {}, objective = {}'.format(n_iter, obj))\n",
    "            n_iter += 1\n",
    "\n",
    "        return self\n",
    "\n",
    "    def get_n_documents(self, X, n = 5):\n",
    "        '''\n",
    "            this method returns the index of top n documents from each cluster\n",
    "            input =>\n",
    "                - X input data matrix (n * d dims)\n",
    "                - n: number of top documents to return\n",
    "            output: =>\n",
    "                - results: list of tuple (k, index) which means doc at index belongs to cluster k\n",
    "        '''\n",
    "        if type(X) == scipy.sparse.csr.csr_matrix:\n",
    "            X = X.toarray()\n",
    "        labels = self.transform(X)\n",
    "        results = []\n",
    "        for k in range(self.K):\n",
    "            idx = search(X, self.centroids[k], self.dist, n)\n",
    "            for i in idx:\n",
    "                results.append((k, i))\n",
    "        return results\n",
    "\n",
    "    ## all the methods below are required for the integration with scikit-learn.\n",
    "    ## DO NOT EDIT ANY METHOD BELOW HERE\n",
    "    def transform(self, X, y = None):\n",
    "        '''\n",
    "            this method returns the labels by inferencing on fitted model\n",
    "            input =>\n",
    "                - X : data matrix (n * d dims)\n",
    "            output: =>\n",
    "                - labels: inferred models\n",
    "        '''\n",
    "        if type(X) == scipy.sparse.csr.csr_matrix:\n",
    "            X = X.toarray()\n",
    "        return self.reassign(X)\n",
    "\n",
    "    def fit_transform(self, X, y = None):\n",
    "        '''\n",
    "            this method returns the labels by fitting X to the model\n",
    "            input =>\n",
    "                - X : data matrix (n * d dims)\n",
    "            output: =>\n",
    "                - labels: inferred models\n",
    "        '''\n",
    "        self.fit(X)\n",
    "        return self.labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the Kmeans class that you have just implemented and we create a `scikit-learn pipeline` which performs clustering with the  TF-IDF document representation and the cosine distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "## encoding dataset labels (refer classifier tutorial)\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(dataset.category)\n",
    "\n",
    "## bag of words vectorizer (refer classifier tutorial)\n",
    "bow_vectorizer = CountVectorizer(lowercase = False, \n",
    "                                     tokenizer = lambda x: x, # because we already have tokens available\n",
    "                                     stop_words = None, ## stop words removal already done from NLTK\n",
    "                                     max_features = 5000, ## pick top 5K words by frequency\n",
    "                                     ngram_range = (1, 1), ## we want unigrams now\n",
    "                                     binary = False) ## Now it's Bag of Words\n",
    "\n",
    "## build a pipeline\n",
    "pipeline_cosine = Pipeline([\n",
    "    ('bow',  bow_vectorizer),\n",
    "    ('tfidf',  TfidfTransformer()),\n",
    "    ('k-means',  KMeans(K = len(list(le.classes_)), distance = 'cosine', tol = 1e-4) ) ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Training KMeans\n",
    "We can now perform training by calling `pipeline.fit` function and get the predictions by calling `pipeline.transform` function.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter = 0, objective = 2339.5134125002232\n",
      "iter = 1, objective = 2312.5453447731747\n",
      "iter = 2, objective = 2301.6123327682067\n",
      "iter = 3, objective = 2294.6393210200013\n",
      "iter = 4, objective = 2290.5622134460255\n",
      "iter = 5, objective = 2288.7791208280896\n",
      "iter = 6, objective = 2287.8622347886094\n",
      "iter = 7, objective = 2287.734803315011\n",
      "iter = 8, objective = 2287.690632932583\n",
      "iter = 9, objective = 2287.658659252548\n",
      "iter = 10, objective = 2287.648761125131\n",
      "iter = 11, objective = 2287.6435805526316\n",
      "iter = 12, objective = 2287.6435805526316\n"
     ]
    }
   ],
   "source": [
    "pipeline_cosine.fit(dataset.tokens)\n",
    "preds_cosine = pipeline_cosine.transform(dataset.tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Get top 5 documents from each cluster\n",
    "\n",
    "Now using the function *get_n_documents*, find and print the top 5 documents from each cluster. We can get individual component of pipeline using function `pipeline.named_steps['k-means']`.\n",
    "\n",
    "Before using this function, we need to access the vectorial representation of the dataset. \n",
    "Since we used a pipeline to do both the document vectorization and the clustering together, we will repeat the process without the last step (i.e. the clustering)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer = Pipeline(pipeline_cosine.steps[:-1]) ## all components of pipeline except last component, which is kmeans\n",
    "vectors = vectorizer.transform(dataset.tokens)\n",
    "top_5_idxs = pipeline_cosine.named_steps['k-means'].get_n_documents(vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output the top 5 documents in each cluster (the 5 documents closest to the centroid, in each cluster)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(rec.motorcycles, 104548) belongs to cluster 0\n",
      "(rec.motorcycles, 104701) belongs to cluster 0\n",
      "(rec.motorcycles, 102616) belongs to cluster 0\n",
      "(rec.motorcycles, 105141) belongs to cluster 0\n",
      "(rec.motorcycles, 104630) belongs to cluster 0\n",
      "(talk.politics.guns, 55067) belongs to cluster 1\n",
      "(talk.politics.guns, 54273) belongs to cluster 1\n",
      "(talk.politics.guns, 55087) belongs to cluster 1\n",
      "(talk.politics.guns, 54329) belongs to cluster 1\n",
      "(talk.politics.guns, 54665) belongs to cluster 1\n",
      "(misc.forsale, 76554) belongs to cluster 2\n",
      "(misc.forsale, 76282) belongs to cluster 2\n",
      "(misc.forsale, 76602) belongs to cluster 2\n",
      "(misc.forsale, 76014) belongs to cluster 2\n",
      "(misc.forsale, 75949) belongs to cluster 2\n"
     ]
    }
   ],
   "source": [
    "for (k, idx) in top_5_idxs:\n",
    "    print(\"({}, {}) belongs to cluster {}\".format(dataset.iloc[idx].category, dataset.iloc[idx].id, k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does a cluster contains only documents from a single document category? \n",
    "Ideally, documents from the same category should belong to the same cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Evaluating cluster performance\n",
    "There are several cluster evaluating metrics readily available in `sklearn.metrics.cluster`, including the `homogeneity_score`, which is similar to the purity measure covered in the lecture.\n",
    "A partition resulted from clustering obtains a homogeneity score of 1 if all of its clusters contain only data points which are members of a single class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "homogenity = 0.8286466402173608\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.cluster import homogeneity_score\n",
    "\n",
    "print(\"homogenity = {}\".format(\n",
    "    homogeneity_score(y, preds_cosine)) \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Additional assignment tasks\n",
    "\n",
    "This section contains three additional tasks. \n",
    "Note that for each of the tasks, you are required to solve each of the three steps here below, each in its own cell:\n",
    "1. construct a processing pipeline (as shown in the tutorials) which solves the task, \n",
    "2. compute and print the homogeneity score obtained using the pipeline\n",
    "3. plot the barplot of this score against the score obtained by the implementation in Section 2\n",
    "\n",
    "### 3.1 Task 2: Compare the KMeans clustering when using Unigrams vs. Bigrams as features.\n",
    "The KMeans clustering that we tested in Section 2 used Unigrams as representation features.\n",
    "Implement a processing pipeline which uses Bigrams as features and compare the performance gain (or loss) w.r.t. Unigrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter = 0, objective = 2385.6807846101174\n",
      "iter = 1, objective = 2363.533373009953\n",
      "iter = 2, objective = 2358.3553425470272\n",
      "iter = 3, objective = 2355.572897393895\n",
      "iter = 4, objective = 2353.749072538189\n",
      "iter = 5, objective = 2352.4712646568973\n",
      "iter = 6, objective = 2350.862928068388\n",
      "iter = 7, objective = 2348.346585738317\n",
      "iter = 8, objective = 2346.356561807081\n",
      "iter = 9, objective = 2345.8086546962522\n",
      "iter = 10, objective = 2345.6366048845025\n",
      "iter = 11, objective = 2345.56312296158\n",
      "iter = 12, objective = 2345.48177975093\n",
      "iter = 13, objective = 2345.371664793164\n",
      "iter = 14, objective = 2345.0461718615916\n",
      "iter = 15, objective = 2344.110527264365\n",
      "iter = 16, objective = 2344.0509905722765\n",
      "iter = 17, objective = 2344.0453405987128\n",
      "iter = 18, objective = 2344.0453405987128\n"
     ]
    }
   ],
   "source": [
    "## bag of words vectorizer (refer classifier tutorial)\n",
    "bigrams_bow_vectorizer = CountVectorizer(lowercase = False, \n",
    "                                     tokenizer = lambda x: x, # because we already have tokens available\n",
    "                                     stop_words = None, ## stop words removal already done from NLTK\n",
    "                                     max_features = 13000, ## pick top 20K tokens by frequency. We need more now.\n",
    "                                     ngram_range = (1, 2), ## we want unigrams bigrams now\n",
    "                                     binary = True) ## Now it's Bag of Words\n",
    "\n",
    "## build a pipeline\n",
    "pipeline_bigrams = Pipeline([\n",
    "    ('bigram_bow',  bigrams_bow_vectorizer),\n",
    "    ('tfidf',  TfidfTransformer()),\n",
    "    ('k-means',  KMeans(K = len(list(le.classes_)), distance = 'cosine', tol = 1e-4) ) ])\n",
    "\n",
    "pipeline_bigrams.fit(dataset.tokens)\n",
    "preds_bigrams = pipeline_bigrams.transform(dataset.tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "homogenity = 0.8408953338568459\n"
     ]
    }
   ],
   "source": [
    "## TODO: compute homogeneity\n",
    "\n",
    "print(\"homogenity = {}\".format(\n",
    "    homogeneity_score(y, preds_bigrams)) \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x11bf97e80>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAEvCAYAAABFZrb+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ndA4kA0WxNwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11b802eb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## TODO: barplot performances of BIGRAMS (this task) vs. UNIGRAMS (computed in Section 2)\n",
    "homogeneity_unigrams = homogeneity_score(y, preds_cosine)\n",
    "homogeneity_bigrams = homogeneity_score(y, preds_bigrams)\n",
    "\n",
    "accuracies = pd.DataFrame(\n",
    "    [('unigrams', homogeneity_unigrams),  ('bigrams', homogeneity_bigrams)], \n",
    "    columns = ['n-grams', 'homogeneity']\n",
    ").set_index('n-grams')\n",
    "accuracies.plot.bar(ylim = (0.7, 0.9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 3.2 Task 3: Cosine vs Euclidean distance.\n",
    "The algorithm in Section 2 used the Cosine distance to measure similarity between document (and/or centroids).\n",
    "In this task, you will measure the performance gain/loss when using the Euclidean distance instead.\n",
    "\n",
    "**Hint:** use the adequate argument in K-Means constructor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter = 0, objective = 2825.9149562483844\n",
      "iter = 1, objective = 2819.8447925245864\n",
      "iter = 2, objective = 2818.505085351282\n",
      "iter = 3, objective = 2818.205790732381\n",
      "iter = 4, objective = 2818.0849804319587\n",
      "iter = 5, objective = 2818.026191883132\n",
      "iter = 6, objective = 2817.9923629972595\n",
      "iter = 7, objective = 2817.9774188909796\n",
      "iter = 8, objective = 2817.9641714861646\n",
      "iter = 9, objective = 2817.956836320286\n",
      "iter = 10, objective = 2817.9513553575957\n",
      "iter = 11, objective = 2817.9513553575957\n"
     ]
    }
   ],
   "source": [
    "## TODO: implement KMEANS with Euclidean\n",
    "\n",
    "pipeline_euclid = Pipeline([\n",
    "    ('bow',  bow_vectorizer),\n",
    "    ('tfidf',  TfidfTransformer()),\n",
    "    ('k-means',  KMeans(K = len(list(le.classes_)), distance = 'euclid', tol = 1e-4) ) ])\n",
    "pipeline_euclid.fit(dataset.tokens)\n",
    "preds_euclid = pipeline_euclid.transform(dataset.tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "homogenity = 0.7826681114786379\n"
     ]
    }
   ],
   "source": [
    "## TODO: compute homogeneity\n",
    "print(\"homogenity = {}\".format(\n",
    "    homogeneity_score(y, preds_euclid)) \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1362aecc0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAEgCAYAAAC0MAQrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZmaWOBDMzAxwIJiZWfL/AUWYsXewBuYMAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1369f9b38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## TODO: barplot performances of EUCLIDEAN (this task) vs. COSINE (computed in Section 2)\n",
    "homogeneity_euclid = homogeneity_score(y, preds_euclid)\n",
    "\n",
    "accuracies = pd.DataFrame(\n",
    "    [('cosine', homogeneity_unigrams),  ('euclid', homogeneity_euclid)], \n",
    "    columns = ['distance measure', 'homogeneity']\n",
    ").set_index('distance measure')\n",
    "accuracies.plot.bar(ylim = (0.7, 0.9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Task 4: compare against the K-Means implementation in `scikit-learn`\n",
    "As you might have surely doubted, a mature library such as `scikit-learn` contains a readily implementation of KMeans.\n",
    "In this task, you will compare our homegrown KMeans implementation with the `scikit-learn`'s KMeans.\n",
    "\n",
    "**Hint** you might want to look at [this for reference](http://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## TODO: use KMeans from scikit-learn\n",
    "import sklearn.cluster\n",
    "\n",
    "pipeline_sl = Pipeline([\n",
    "    ('bow',  bow_vectorizer),\n",
    "    ('tfidf',  TfidfTransformer()),\n",
    "    ('k-means',  sklearn.cluster.KMeans(n_clusters=len(list(le.classes_)), n_init=1))])\n",
    "\n",
    "pipeline_sl.fit(dataset.tokens)\n",
    "preds_sl = pipeline_sl.fit_predict(dataset.tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "homogenity = 0.717671489404739\n"
     ]
    }
   ],
   "source": [
    "## TODO: compute homogeneity\n",
    "print(\"homogenity = {}\".format(\n",
    "    homogeneity_score(y, preds_sl)) \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x136160b00>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAFPCAYAAABNkrmkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x13613fba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## TODO: barplot performances of scikit-learn KMeans (this task) vs. our own (computed in Section 2)\n",
    "homogeneity_sl = homogeneity_score(y, preds_sl)\n",
    "\n",
    "accuracies = pd.DataFrame(\n",
    "    [('our homegrown', homogeneity_unigrams),  ('scikit-learn', homogeneity_sl)], \n",
    "    columns = ['Kmeans', 'homogeneity']\n",
    ").set_index('Kmeans')\n",
    "accuracies.plot.bar(ylim = (0.7, 0.9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Play with the parameters of the `scikit-learn` KMeans function and improve its performances. What do you need to do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "homogenity = 0.7534181791022208\n"
     ]
    }
   ],
   "source": [
    "pipeline_sl_advanced = Pipeline([\n",
    "    ('bow',  bow_vectorizer),\n",
    "    ('tfidf',  TfidfTransformer()),\n",
    "    ('k-means',  sklearn.cluster.KMeans(n_clusters=len(list(le.classes_)), n_init=20, tol=0))])\n",
    "\n",
    "pipeline_sl_advanced.fit(dataset.tokens)\n",
    "preds_sl_advanced = pipeline_sl_advanced.fit_predict(dataset.tokens)\n",
    "print(\"homogenity = {}\".format(\n",
    "    homogeneity_score(y, preds_sl_advanced)) \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
