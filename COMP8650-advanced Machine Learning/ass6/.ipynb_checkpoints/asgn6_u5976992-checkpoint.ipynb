{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP8650 Assignment 6\n",
    "u5976992, Longfei Zhao\n",
    "\n",
    "## 1. Conv2d and ConvTranspose2d\n",
    "\n",
    "### a)\n",
    "\n",
    "$H_{out}$ = $\\left\\lfloor{\\frac{H_{in} + 2 × {\\rm padding} - ({\\rm kernel\\_size} - 1) - 1}{\\rm stride} + 1} \\right\\rfloor$ = 64\n",
    "\n",
    "$W_{out}$ = $\\left\\lfloor{\\frac{W_{in} + 2 × {\\rm padding} - ({\\rm kernel\\_size} - 1) - 1}{\\rm stride} + 1} \\right\\rfloor$ = 64\n",
    "\n",
    "$C_{out}$ = 16\n",
    "\n",
    "output size = (32, 16, 65, 65)\n",
    "\n",
    "### b)\n",
    "$H_{out}$ = ($H_{in}$ − 1) × stride − 2 × padding + kernel_size + output_padding = 3\n",
    "\n",
    "$W_{out}$ = ($W_{in}$ − 1) × stride − 2 × padding + kernel_size + output_padding = 3\n",
    "\n",
    "$C_{out}$ = 128\n",
    "\n",
    "output size = (32, 128, 3, 3)\n",
    "\n",
    "### c)\n",
    "$H_{out}$ = ($H_{in}$−1) × stride − 2 × padding + kernel_size + output_padding = 65\n",
    "\n",
    "$W_{out}$ = ($W_{in}$−1) × stride − 2 × padding + kernel_size + output_padding = 65\n",
    "\n",
    "$C_{out}$ = 32\n",
    "\n",
    "output size = (32, 32, 65, 65)\n",
    "\n",
    "### d)\n",
    "\n",
    "the shape of weight = ($C_{out}$, $C_{in}$, kernel_size, kernel_size) = (16, 3, 3, 3)\n",
    "\n",
    "the shape of bias = $C_{out}$ = 16\n",
    "\n",
    "the number of learnable parameters = the number of weight + the number of bias = 16 × 3 × 3 × 3 + 16 = 448\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMP4680/8650: ADVANCED TOPICS IN STATISTICAL MACHINE LEARNING\n",
    "# ASSIGNMENT 6\n",
    "#\n",
    "# ONLY MODIFY CODE IN THIS FILE\n",
    "#\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    \"\"\"Encoder network to map from an RGB image to a latent feature vector.\"\"\"\n",
    "\n",
    "    def __init__(self, z_dim=64, img_size=64):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.z_dim = z_dim\n",
    "        self.hidden_layer = nn.Sequential(\n",
    "            nn.Linear(img_size * img_size * 3, z_dim),\n",
    "            nn.BatchNorm1d(z_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.output_layer = nn.Sequential(\n",
    "            nn.Linear(z_dim, z_dim),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size()[0], -1)\n",
    "        x = self.output_layer(self.hidden_layer(x))\n",
    "        return x\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    \"\"\"Decoder network to map from a latent feature vector to an RGB image.\"\"\"\n",
    "\n",
    "    def __init__(self, z_dim=64, img_size=64):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        assert img_size==64\n",
    "        self.z_dim = z_dim\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(z_dim, 128, 7, stride=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 128, 3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(128, 64, 3, stride=2),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, 3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(64, 64, 3, stride=2),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, 3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(64, 32, 3, stride=2),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 32, 3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.layer5 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(32, 32, 2, stride=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 3, 1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size()[0], self.z_dim, 1, 1)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.layer5(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Experiments\n",
    "### a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 1.370s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "%run test_models.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keeping models on CPU.\n",
      "Started training at Sun Oct 28 00:48:37 2018\n",
      "Iteration [    10/  3500] | loss: 0.5035\n",
      "Iteration [    20/  3500] | loss: 0.3876\n",
      "Iteration [    30/  3500] | loss: 0.3255\n",
      "Iteration [    40/  3500] | loss: 0.2740\n",
      "Iteration [    50/  3500] | loss: 0.2358\n",
      "Iteration [    60/  3500] | loss: 0.2132\n",
      "Iteration [    70/  3500] | loss: 0.2151\n",
      "Iteration [    80/  3500] | loss: 0.1872\n",
      "Iteration [    90/  3500] | loss: 0.1771\n",
      "Iteration [   100/  3500] | loss: 0.1747\n",
      "Saved samples/sample-000100.png\n",
      "Saved samples/novel-000100.png\n",
      "Iteration [   110/  3500] | loss: 0.1560\n",
      "Iteration [   120/  3500] | loss: 0.1569\n",
      "Iteration [   130/  3500] | loss: 0.1611\n",
      "Iteration [   140/  3500] | loss: 0.1618\n",
      "Iteration [   150/  3500] | loss: 0.1511\n",
      "Iteration [   160/  3500] | loss: 0.1427\n",
      "Iteration [   170/  3500] | loss: 0.1373\n",
      "Iteration [   180/  3500] | loss: 0.1322\n",
      "Iteration [   190/  3500] | loss: 0.1318\n",
      "Iteration [   200/  3500] | loss: 0.1447\n",
      "Saved samples/sample-000200.png\n",
      "Saved samples/novel-000200.png\n",
      "Iteration [   210/  3500] | loss: 0.1205\n",
      "Iteration [   220/  3500] | loss: 0.1241\n",
      "Iteration [   230/  3500] | loss: 0.1247\n",
      "Iteration [   240/  3500] | loss: 0.1117\n",
      "Iteration [   250/  3500] | loss: 0.1142\n",
      "Iteration [   260/  3500] | loss: 0.1232\n",
      "Iteration [   270/  3500] | loss: 0.1246\n",
      "Iteration [   280/  3500] | loss: 0.1045\n",
      "Iteration [   290/  3500] | loss: 0.1187\n",
      "Iteration [   300/  3500] | loss: 0.1083\n",
      "Saved samples/sample-000300.png\n",
      "Saved samples/novel-000300.png\n",
      "Iteration [   310/  3500] | loss: 0.1139\n",
      "Iteration [   320/  3500] | loss: 0.1127\n",
      "Iteration [   330/  3500] | loss: 0.1165\n",
      "Iteration [   340/  3500] | loss: 0.0993\n",
      "Iteration [   350/  3500] | loss: 0.1074\n",
      "Iteration [   360/  3500] | loss: 0.1129\n",
      "Iteration [   370/  3500] | loss: 0.1121\n",
      "Iteration [   380/  3500] | loss: 0.1056\n",
      "Iteration [   390/  3500] | loss: 0.1047\n",
      "Iteration [   400/  3500] | loss: 0.1170\n",
      "Saved samples/sample-000400.png\n",
      "Saved samples/novel-000400.png\n",
      "Iteration [   410/  3500] | loss: 0.1295\n",
      "Iteration [   420/  3500] | loss: 0.1289\n",
      "Iteration [   430/  3500] | loss: 0.0903\n",
      "Iteration [   440/  3500] | loss: 0.1042\n",
      "Iteration [   450/  3500] | loss: 0.0989\n",
      "Iteration [   460/  3500] | loss: 0.0965\n",
      "Iteration [   470/  3500] | loss: 0.0980\n",
      "Iteration [   480/  3500] | loss: 0.1012\n",
      "Iteration [   490/  3500] | loss: 0.0907\n",
      "Iteration [   500/  3500] | loss: 0.0974\n",
      "Saved samples/sample-000500.png\n",
      "Saved samples/novel-000500.png\n",
      "Iteration [   510/  3500] | loss: 0.0766\n",
      "Iteration [   520/  3500] | loss: 0.0836\n",
      "Iteration [   530/  3500] | loss: 0.0994\n",
      "Iteration [   540/  3500] | loss: 0.0868\n",
      "Iteration [   550/  3500] | loss: 0.0841\n",
      "Iteration [   560/  3500] | loss: 0.0946\n",
      "Iteration [   570/  3500] | loss: 0.0913\n",
      "Iteration [   580/  3500] | loss: 0.0888\n",
      "Iteration [   590/  3500] | loss: 0.0876\n",
      "Iteration [   600/  3500] | loss: 0.0791\n",
      "Saved samples/sample-000600.png\n",
      "Saved samples/novel-000600.png\n",
      "Iteration [   610/  3500] | loss: 0.0740\n",
      "Iteration [   620/  3500] | loss: 0.0771\n",
      "Iteration [   630/  3500] | loss: 0.1251\n",
      "Iteration [   640/  3500] | loss: 0.0752\n",
      "Iteration [   650/  3500] | loss: 0.0726\n",
      "Iteration [   660/  3500] | loss: 0.0726\n",
      "Iteration [   670/  3500] | loss: 0.0702\n",
      "Iteration [   680/  3500] | loss: 0.0761\n",
      "Iteration [   690/  3500] | loss: 0.0714\n",
      "Iteration [   700/  3500] | loss: 0.0825\n",
      "Saved samples/sample-000700.png\n",
      "Saved samples/novel-000700.png\n",
      "Iteration [   710/  3500] | loss: 0.0737\n",
      "Iteration [   720/  3500] | loss: 0.0762\n",
      "Iteration [   730/  3500] | loss: 0.0763\n",
      "Iteration [   740/  3500] | loss: 0.0932\n",
      "Iteration [   750/  3500] | loss: 0.0699\n",
      "Iteration [   760/  3500] | loss: 0.0803\n",
      "Iteration [   770/  3500] | loss: 0.0838\n",
      "Iteration [   780/  3500] | loss: 0.0657\n",
      "Iteration [   790/  3500] | loss: 0.0712\n",
      "Iteration [   800/  3500] | loss: 0.0637\n",
      "Saved samples/sample-000800.png\n",
      "Saved samples/novel-000800.png\n",
      "Iteration [   810/  3500] | loss: 0.0717\n",
      "Iteration [   820/  3500] | loss: 0.0705\n",
      "Iteration [   830/  3500] | loss: 0.0701\n",
      "Iteration [   840/  3500] | loss: 0.0589\n",
      "Iteration [   850/  3500] | loss: 0.0646\n",
      "Iteration [   860/  3500] | loss: 0.0563\n",
      "Iteration [   870/  3500] | loss: 0.0743\n",
      "Iteration [   880/  3500] | loss: 0.0697\n",
      "Iteration [   890/  3500] | loss: 0.0764\n",
      "Iteration [   900/  3500] | loss: 0.0663\n",
      "Saved samples/sample-000900.png\n",
      "Saved samples/novel-000900.png\n",
      "Iteration [   910/  3500] | loss: 0.0755\n",
      "Iteration [   920/  3500] | loss: 0.0633\n",
      "Iteration [   930/  3500] | loss: 0.0619\n",
      "Iteration [   940/  3500] | loss: 0.0796\n",
      "Iteration [   950/  3500] | loss: 0.0649\n",
      "Iteration [   960/  3500] | loss: 0.0594\n",
      "Iteration [   970/  3500] | loss: 0.0594\n",
      "Iteration [   980/  3500] | loss: 0.0697\n",
      "Iteration [   990/  3500] | loss: 0.0672\n",
      "Iteration [  1000/  3500] | loss: 0.0630\n",
      "Saved samples/sample-001000.png\n",
      "Saved samples/novel-001000.png\n",
      "Iteration [  1010/  3500] | loss: 0.0618\n",
      "Iteration [  1020/  3500] | loss: 0.0593\n",
      "Iteration [  1030/  3500] | loss: 0.0557\n",
      "Iteration [  1040/  3500] | loss: 0.0632\n",
      "Iteration [  1050/  3500] | loss: 0.0752\n",
      "Iteration [  1060/  3500] | loss: 0.0594\n",
      "Iteration [  1070/  3500] | loss: 0.0617\n",
      "Iteration [  1080/  3500] | loss: 0.0695\n",
      "Iteration [  1090/  3500] | loss: 0.0618\n",
      "Iteration [  1100/  3500] | loss: 0.0580\n",
      "Saved samples/sample-001100.png\n",
      "Saved samples/novel-001100.png\n",
      "Iteration [  1110/  3500] | loss: 0.0539\n",
      "Iteration [  1120/  3500] | loss: 0.0698\n",
      "Iteration [  1130/  3500] | loss: 0.0583\n",
      "Iteration [  1140/  3500] | loss: 0.0556\n",
      "Iteration [  1150/  3500] | loss: 0.0700\n",
      "Iteration [  1160/  3500] | loss: 0.0538\n",
      "Iteration [  1170/  3500] | loss: 0.0550\n",
      "Iteration [  1180/  3500] | loss: 0.0554\n",
      "Iteration [  1190/  3500] | loss: 0.0719\n",
      "Iteration [  1200/  3500] | loss: 0.0598\n",
      "Saved samples/sample-001200.png\n",
      "Saved samples/novel-001200.png\n",
      "Iteration [  1210/  3500] | loss: 0.0581\n",
      "Iteration [  1220/  3500] | loss: 0.0569\n",
      "Iteration [  1230/  3500] | loss: 0.0530\n",
      "Iteration [  1240/  3500] | loss: 0.0499\n",
      "Iteration [  1250/  3500] | loss: 0.0564\n",
      "Iteration [  1260/  3500] | loss: 0.0607\n",
      "Iteration [  1270/  3500] | loss: 0.0676\n",
      "Iteration [  1280/  3500] | loss: 0.0512\n",
      "Iteration [  1290/  3500] | loss: 0.0642\n",
      "Iteration [  1300/  3500] | loss: 0.0541\n",
      "Saved samples/sample-001300.png\n",
      "Saved samples/novel-001300.png\n",
      "Iteration [  1310/  3500] | loss: 0.0586\n",
      "Iteration [  1320/  3500] | loss: 0.0531\n",
      "Iteration [  1330/  3500] | loss: 0.0569\n",
      "Iteration [  1340/  3500] | loss: 0.0454\n",
      "Iteration [  1350/  3500] | loss: 0.0504\n",
      "Iteration [  1360/  3500] | loss: 0.0536\n",
      "Iteration [  1370/  3500] | loss: 0.0488\n",
      "Iteration [  1380/  3500] | loss: 0.0537\n",
      "Iteration [  1390/  3500] | loss: 0.0438\n",
      "Iteration [  1400/  3500] | loss: 0.0693\n",
      "Saved samples/sample-001400.png\n",
      "Saved samples/novel-001400.png\n",
      "Iteration [  1410/  3500] | loss: 0.0583\n",
      "Iteration [  1420/  3500] | loss: 0.0525\n",
      "Iteration [  1430/  3500] | loss: 0.0552\n",
      "Iteration [  1440/  3500] | loss: 0.0540\n",
      "Iteration [  1450/  3500] | loss: 0.0464\n",
      "Iteration [  1460/  3500] | loss: 0.0505\n",
      "Iteration [  1470/  3500] | loss: 0.0645\n",
      "Iteration [  1480/  3500] | loss: 0.0558\n",
      "Iteration [  1490/  3500] | loss: 0.0511\n",
      "Iteration [  1500/  3500] | loss: 0.0490\n",
      "Saved samples/sample-001500.png\n",
      "Saved samples/novel-001500.png\n",
      "Iteration [  1510/  3500] | loss: 0.0471\n",
      "Iteration [  1520/  3500] | loss: 0.0535\n",
      "Iteration [  1530/  3500] | loss: 0.0506\n",
      "Iteration [  1540/  3500] | loss: 0.0873\n",
      "Iteration [  1550/  3500] | loss: 0.0484\n",
      "Iteration [  1560/  3500] | loss: 0.0483\n",
      "Iteration [  1570/  3500] | loss: 0.0483\n",
      "Iteration [  1580/  3500] | loss: 0.0423\n",
      "Iteration [  1590/  3500] | loss: 0.0550\n",
      "Iteration [  1600/  3500] | loss: 0.0504\n",
      "Saved samples/sample-001600.png\n",
      "Saved samples/novel-001600.png\n",
      "Iteration [  1610/  3500] | loss: 0.0598\n",
      "Iteration [  1620/  3500] | loss: 0.0515\n",
      "Iteration [  1630/  3500] | loss: 0.0489\n",
      "Iteration [  1640/  3500] | loss: 0.0559\n",
      "Iteration [  1650/  3500] | loss: 0.0461\n",
      "Iteration [  1660/  3500] | loss: 0.0484\n",
      "Iteration [  1670/  3500] | loss: 0.0438\n",
      "Iteration [  1680/  3500] | loss: 0.0606\n",
      "Iteration [  1690/  3500] | loss: 0.0422\n",
      "Iteration [  1700/  3500] | loss: 0.0428\n",
      "Saved samples/sample-001700.png\n",
      "Saved samples/novel-001700.png\n",
      "Iteration [  1710/  3500] | loss: 0.0470\n",
      "Iteration [  1720/  3500] | loss: 0.0440\n",
      "Iteration [  1730/  3500] | loss: 0.0448\n",
      "Iteration [  1740/  3500] | loss: 0.0531\n",
      "Iteration [  1750/  3500] | loss: 0.0653\n",
      "Iteration [  1760/  3500] | loss: 0.0463\n",
      "Iteration [  1770/  3500] | loss: 0.0475\n",
      "Iteration [  1780/  3500] | loss: 0.0472\n",
      "Iteration [  1790/  3500] | loss: 0.0506\n",
      "Iteration [  1800/  3500] | loss: 0.0429\n",
      "Saved samples/sample-001800.png\n",
      "Saved samples/novel-001800.png\n",
      "Iteration [  1810/  3500] | loss: 0.0444\n",
      "Iteration [  1820/  3500] | loss: 0.0519\n",
      "Iteration [  1830/  3500] | loss: 0.0437\n",
      "Iteration [  1840/  3500] | loss: 0.0483\n",
      "Iteration [  1850/  3500] | loss: 0.0393\n",
      "Iteration [  1860/  3500] | loss: 0.0446\n",
      "Iteration [  1870/  3500] | loss: 0.0532\n",
      "Iteration [  1880/  3500] | loss: 0.0399\n",
      "Iteration [  1890/  3500] | loss: 0.0703\n",
      "Iteration [  1900/  3500] | loss: 0.0460\n",
      "Saved samples/sample-001900.png\n",
      "Saved samples/novel-001900.png\n",
      "Iteration [  1910/  3500] | loss: 0.0491\n",
      "Iteration [  1920/  3500] | loss: 0.0498\n",
      "Iteration [  1930/  3500] | loss: 0.0428\n",
      "Iteration [  1940/  3500] | loss: 0.0433\n",
      "Iteration [  1950/  3500] | loss: 0.0446\n",
      "Iteration [  1960/  3500] | loss: 0.0476\n",
      "Iteration [  1970/  3500] | loss: 0.0602\n",
      "Iteration [  1980/  3500] | loss: 0.0527\n",
      "Iteration [  1990/  3500] | loss: 0.0450\n",
      "Iteration [  2000/  3500] | loss: 0.0413\n",
      "Saved samples/sample-002000.png\n",
      "Saved samples/novel-002000.png\n",
      "Iteration [  2010/  3500] | loss: 0.0548\n",
      "Iteration [  2020/  3500] | loss: 0.0483\n",
      "Iteration [  2030/  3500] | loss: 0.0598\n",
      "Iteration [  2040/  3500] | loss: 0.0499\n",
      "Iteration [  2050/  3500] | loss: 0.0489\n",
      "Iteration [  2060/  3500] | loss: 0.0438\n",
      "Iteration [  2070/  3500] | loss: 0.0463\n",
      "Iteration [  2080/  3500] | loss: 0.0435\n",
      "Iteration [  2090/  3500] | loss: 0.0430\n",
      "Iteration [  2100/  3500] | loss: 0.0503\n",
      "Saved samples/sample-002100.png\n",
      "Saved samples/novel-002100.png\n",
      "Iteration [  2110/  3500] | loss: 0.0395\n",
      "Iteration [  2120/  3500] | loss: 0.0467\n",
      "Iteration [  2130/  3500] | loss: 0.0411\n",
      "Iteration [  2140/  3500] | loss: 0.0479\n",
      "Iteration [  2150/  3500] | loss: 0.0447\n",
      "Iteration [  2160/  3500] | loss: 0.0437\n",
      "Iteration [  2170/  3500] | loss: 0.0496\n",
      "Iteration [  2180/  3500] | loss: 0.0435\n",
      "Iteration [  2190/  3500] | loss: 0.0450\n",
      "Iteration [  2200/  3500] | loss: 0.0445\n",
      "Saved samples/sample-002200.png\n",
      "Saved samples/novel-002200.png\n",
      "Iteration [  2210/  3500] | loss: 0.0419\n",
      "Iteration [  2220/  3500] | loss: 0.0502\n",
      "Iteration [  2230/  3500] | loss: 0.0431\n",
      "Iteration [  2240/  3500] | loss: 0.0797\n",
      "Iteration [  2250/  3500] | loss: 0.0432\n",
      "Iteration [  2260/  3500] | loss: 0.0386\n",
      "Iteration [  2270/  3500] | loss: 0.0429\n",
      "Iteration [  2280/  3500] | loss: 0.0404\n",
      "Iteration [  2290/  3500] | loss: 0.0413\n",
      "Iteration [  2300/  3500] | loss: 0.0416\n",
      "Saved samples/sample-002300.png\n",
      "Saved samples/novel-002300.png\n",
      "Iteration [  2310/  3500] | loss: 0.0500\n",
      "Iteration [  2320/  3500] | loss: 0.0487\n",
      "Iteration [  2330/  3500] | loss: 0.0405\n",
      "Iteration [  2340/  3500] | loss: 0.0455\n",
      "Iteration [  2350/  3500] | loss: 0.0406\n",
      "Iteration [  2360/  3500] | loss: 0.0416\n",
      "Iteration [  2370/  3500] | loss: 0.0383\n",
      "Iteration [  2380/  3500] | loss: 0.0424\n",
      "Iteration [  2390/  3500] | loss: 0.0431\n",
      "Iteration [  2400/  3500] | loss: 0.0469\n",
      "Saved samples/sample-002400.png\n",
      "Saved samples/novel-002400.png\n",
      "Iteration [  2410/  3500] | loss: 0.0399\n",
      "Iteration [  2420/  3500] | loss: 0.0441\n",
      "Iteration [  2430/  3500] | loss: 0.0501\n",
      "Iteration [  2440/  3500] | loss: 0.0419\n",
      "Iteration [  2450/  3500] | loss: 0.0474\n",
      "Iteration [  2460/  3500] | loss: 0.0417\n",
      "Iteration [  2470/  3500] | loss: 0.0400\n",
      "Iteration [  2480/  3500] | loss: 0.0372\n",
      "Iteration [  2490/  3500] | loss: 0.0380\n",
      "Iteration [  2500/  3500] | loss: 0.0395\n",
      "Saved samples/sample-002500.png\n",
      "Saved samples/novel-002500.png\n",
      "Iteration [  2510/  3500] | loss: 0.0414\n",
      "Iteration [  2520/  3500] | loss: 0.0382\n",
      "Iteration [  2530/  3500] | loss: 0.0403\n",
      "Iteration [  2540/  3500] | loss: 0.0362\n",
      "Iteration [  2550/  3500] | loss: 0.0377\n",
      "Iteration [  2560/  3500] | loss: 0.0434\n",
      "Iteration [  2570/  3500] | loss: 0.0455\n",
      "Iteration [  2580/  3500] | loss: 0.0394\n",
      "Iteration [  2590/  3500] | loss: 0.0458\n",
      "Iteration [  2600/  3500] | loss: 0.0393\n",
      "Saved samples/sample-002600.png\n",
      "Saved samples/novel-002600.png\n",
      "Iteration [  2610/  3500] | loss: 0.0360\n",
      "Iteration [  2620/  3500] | loss: 0.0407\n",
      "Iteration [  2630/  3500] | loss: 0.0392\n",
      "Iteration [  2640/  3500] | loss: 0.0363\n",
      "Iteration [  2650/  3500] | loss: 0.0391\n",
      "Iteration [  2660/  3500] | loss: 0.0577\n",
      "Iteration [  2670/  3500] | loss: 0.0403\n",
      "Iteration [  2680/  3500] | loss: 0.0383\n",
      "Iteration [  2690/  3500] | loss: 0.0405\n",
      "Iteration [  2700/  3500] | loss: 0.0412\n",
      "Saved samples/sample-002700.png\n",
      "Saved samples/novel-002700.png\n",
      "Iteration [  2710/  3500] | loss: 0.0448\n",
      "Iteration [  2720/  3500] | loss: 0.0420\n",
      "Iteration [  2730/  3500] | loss: 0.0454\n",
      "Iteration [  2740/  3500] | loss: 0.0501\n",
      "Iteration [  2750/  3500] | loss: 0.0392\n",
      "Iteration [  2760/  3500] | loss: 0.0378\n",
      "Iteration [  2770/  3500] | loss: 0.0456\n",
      "Iteration [  2780/  3500] | loss: 0.0400\n",
      "Iteration [  2790/  3500] | loss: 0.0415\n",
      "Iteration [  2800/  3500] | loss: 0.0418\n",
      "Saved samples/sample-002800.png\n",
      "Saved samples/novel-002800.png\n",
      "Iteration [  2810/  3500] | loss: 0.0400\n",
      "Iteration [  2820/  3500] | loss: 0.0396\n",
      "Iteration [  2830/  3500] | loss: 0.0399\n",
      "Iteration [  2840/  3500] | loss: 0.0443\n",
      "Iteration [  2850/  3500] | loss: 0.0391\n",
      "Iteration [  2860/  3500] | loss: 0.0358\n",
      "Iteration [  2870/  3500] | loss: 0.0493\n",
      "Iteration [  2880/  3500] | loss: 0.0387\n",
      "Iteration [  2890/  3500] | loss: 0.0342\n",
      "Iteration [  2900/  3500] | loss: 0.0386\n",
      "Saved samples/sample-002900.png\n",
      "Saved samples/novel-002900.png\n",
      "Iteration [  2910/  3500] | loss: 0.0359\n",
      "Iteration [  2920/  3500] | loss: 0.0405\n",
      "Iteration [  2930/  3500] | loss: 0.0357\n",
      "Iteration [  2940/  3500] | loss: 0.0573\n",
      "Iteration [  2950/  3500] | loss: 0.0372\n",
      "Iteration [  2960/  3500] | loss: 0.0340\n",
      "Iteration [  2970/  3500] | loss: 0.0354\n",
      "Iteration [  2980/  3500] | loss: 0.0371\n",
      "Iteration [  2990/  3500] | loss: 0.0358\n",
      "Iteration [  3000/  3500] | loss: 0.0318\n",
      "Saved samples/sample-003000.png\n",
      "Saved samples/novel-003000.png\n",
      "Iteration [  3010/  3500] | loss: 0.0511\n",
      "Iteration [  3020/  3500] | loss: 0.0400\n",
      "Iteration [  3030/  3500] | loss: 0.0394\n",
      "Iteration [  3040/  3500] | loss: 0.0360\n",
      "Iteration [  3050/  3500] | loss: 0.0333\n",
      "Iteration [  3060/  3500] | loss: 0.0354\n",
      "Iteration [  3070/  3500] | loss: 0.0359\n",
      "Iteration [  3080/  3500] | loss: 0.0504\n",
      "Iteration [  3090/  3500] | loss: 0.0314\n",
      "Iteration [  3100/  3500] | loss: 0.0337\n",
      "Saved samples/sample-003100.png\n",
      "Saved samples/novel-003100.png\n",
      "Iteration [  3110/  3500] | loss: 0.0336\n",
      "Iteration [  3120/  3500] | loss: 0.0321\n",
      "Iteration [  3130/  3500] | loss: 0.0362\n",
      "Iteration [  3140/  3500] | loss: 0.0373\n",
      "Iteration [  3150/  3500] | loss: 0.0751\n",
      "Iteration [  3160/  3500] | loss: 0.0324\n",
      "Iteration [  3170/  3500] | loss: 0.0366\n",
      "Iteration [  3180/  3500] | loss: 0.0348\n",
      "Iteration [  3190/  3500] | loss: 0.0331\n",
      "Iteration [  3200/  3500] | loss: 0.0355\n",
      "Saved samples/sample-003200.png\n",
      "Saved samples/novel-003200.png\n",
      "Iteration [  3210/  3500] | loss: 0.0333\n",
      "Iteration [  3220/  3500] | loss: 0.0483\n",
      "Iteration [  3230/  3500] | loss: 0.0333\n",
      "Iteration [  3240/  3500] | loss: 0.0360\n",
      "Iteration [  3250/  3500] | loss: 0.0545\n",
      "Iteration [  3260/  3500] | loss: 0.0376\n",
      "Iteration [  3270/  3500] | loss: 0.0399\n",
      "Iteration [  3280/  3500] | loss: 0.0339\n",
      "Iteration [  3290/  3500] | loss: 0.0399\n",
      "Iteration [  3300/  3500] | loss: 0.0414\n",
      "Saved samples/sample-003300.png\n",
      "Saved samples/novel-003300.png\n",
      "Iteration [  3310/  3500] | loss: 0.0364\n",
      "Iteration [  3320/  3500] | loss: 0.0372\n",
      "Iteration [  3330/  3500] | loss: 0.0371\n",
      "Iteration [  3340/  3500] | loss: 0.0346\n",
      "Iteration [  3350/  3500] | loss: 0.0358\n",
      "Iteration [  3360/  3500] | loss: 0.0493\n",
      "Iteration [  3370/  3500] | loss: 0.0355\n",
      "Iteration [  3380/  3500] | loss: 0.0351\n",
      "Iteration [  3390/  3500] | loss: 0.0371\n",
      "Iteration [  3400/  3500] | loss: 0.0380\n",
      "Saved samples/sample-003400.png\n",
      "Saved samples/novel-003400.png\n",
      "Iteration [  3410/  3500] | loss: 0.0341\n",
      "Iteration [  3420/  3500] | loss: 0.0387\n",
      "Iteration [  3430/  3500] | loss: 0.0434\n",
      "Iteration [  3440/  3500] | loss: 0.0449\n",
      "Iteration [  3450/  3500] | loss: 0.0384\n",
      "Iteration [  3460/  3500] | loss: 0.0400\n",
      "Iteration [  3470/  3500] | loss: 0.0308\n",
      "Iteration [  3480/  3500] | loss: 0.0343\n",
      "Iteration [  3490/  3500] | loss: 0.0388\n",
      "Iteration [  3500/  3500] | loss: 0.0358\n",
      "Saved samples/sample-003500.png\n",
      "Saved samples/novel-003500.png\n"
     ]
    }
   ],
   "source": [
    "%run asgn6.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) Plot the loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"loss_fig.png\">\n",
    "<img src=\"log_loss_fig.png\">\n",
    "\n",
    "According to trend of the log_loss curve, I think it's not converged."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d)\n",
    "<img src='sample-000100.png' align=\"center\">\n",
    "\n",
    "***sample-000100***: After 100 training, the donoised images just get a blurry outline. They are basically useless. The quality of the denoised images are much worse than the noisy input images.\n",
    "\n",
    "<img src='sample-000700.png'>\n",
    "\n",
    "***sample-000700***: After 700 training, color appears in the donoised images but very blurry. For some images, we can roughly find where is the head or leg but there are no many details. Most of details miss in the donoised images. Comparing with the noisy input images, we can see that the quality of the denoised images are still worse than the noisy input images.\n",
    "\n",
    "<img src='sample-001400.png'>\n",
    "\n",
    "***sample-001400***: After 1400 training, I would say that the quality of the denoised images are basically same as the noisy input images. It recovered many details.\n",
    "\n",
    "After about 1000 training, more and more images are recovered pretty good. However, I think the denoised images are still worst than noisy input images since we can see \n",
    "After about 3000 training, I think the quality of the denoised images are better than noisy input images \n",
    "\n",
    "<img src='sample-003500.png'>\n",
    "\n",
    "***sample-003500***: In the end, I would say that the quality of the denoised images are better than the noisy input images. Some anamorphic details and color are recovered pretty good. For many images, I can easily tell which Pokemon it is. However, we should know it's still have a big gap with the ground-truth images. For example, the second one. It's too complex and its noisy input image is already hard to distinguish."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e)\n",
    "\n",
    "At the beginning, the images are grey-scale and just some simple outline. With training, it's more and more colorful and the shape of it are more and more complex. I would say that about after 700 training, the novel images look like something. We can easily imagine where is the head, the body, the wing, the tail and the leg."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
